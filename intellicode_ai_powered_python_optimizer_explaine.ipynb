{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYlHKr82Tffxw64l+fwzXE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vinaykumar21798/IntelliCode-AI-Powered-Python-Optimizer-Explainer/blob/main/intellicode_ai_powered_python_optimizer_explaine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FR0FLuvdyan9",
        "outputId": "24548c2d-a612-4b30-da36-325d94d1807b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AIzaSyCV6BN7LpZONiyMVFKX0NiJd5xKlAD8va0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "    print(m.name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M1j7hjYa1Eus",
        "outputId": "6277c12c-1994-467c-fb39-3f9796980092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/embedding-gecko-001\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-05-20\n",
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-flash-lite-preview-06-17\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.5-pro-preview-06-05\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-preview-image-generation\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-flash-latest\n",
            "models/gemini-flash-lite-latest\n",
            "models/gemini-pro-latest\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image-preview\n",
            "models/gemini-2.5-flash-image\n",
            "models/gemini-2.5-flash-preview-09-2025\n",
            "models/gemini-2.5-flash-lite-preview-09-2025\n",
            "models/gemini-robotics-er-1.5-preview\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/gemini-embedding-exp-03-07\n",
            "models/gemini-embedding-exp\n",
            "models/gemini-embedding-001\n",
            "models/aqa\n",
            "models/imagen-3.0-generate-002\n",
            "models/imagen-4.0-generate-preview-06-06\n",
            "models/imagen-4.0-ultra-generate-preview-06-06\n",
            "models/imagen-4.0-generate-001\n",
            "models/imagen-4.0-ultra-generate-001\n",
            "models/imagen-4.0-fast-generate-001\n",
            "models/veo-2.0-generate-001\n",
            "models/veo-3.0-generate-preview\n",
            "models/veo-3.0-fast-generate-preview\n",
            "models/veo-3.0-generate-001\n",
            "models/veo-3.0-fast-generate-001\n",
            "models/gemini-2.5-flash-preview-native-audio-dialog\n",
            "models/gemini-2.5-flash-exp-native-audio-thinking-dialog\n",
            "models/gemini-2.0-flash-live-001\n",
            "models/gemini-live-2.5-flash-preview\n",
            "models/gemini-2.5-flash-live-preview\n",
            "models/gemini-2.5-flash-native-audio-latest\n",
            "models/gemini-2.5-flash-native-audio-preview-09-2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IntelliCode Explainer - Advanced Colab Notebook Script\n",
        "# Paste this cell into Google Colab and run.\n",
        "# Requirements: google.generativeai installed in the environment (Colab usually has it)\n",
        "# Make sure you add GEMINI_API_KEY in Colab Secrets (sidebar -> Secrets).\n",
        "\n",
        "# --- IMPORTS ---\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata, files\n",
        "from IPython.display import Markdown, display\n",
        "import ast\n",
        "import textwrap\n",
        "import math\n",
        "import sys\n",
        "import traceback\n",
        "\n",
        "# --- CONFIGURATION & HELPERS ---\n",
        "DEFAULT_MODEL_PREFERENCES = [\n",
        "    \"models/gemini-2.5-flash\",\n",
        "    \"models/gemini-2.5-pro\",\n",
        "    \"models/gemini-flash-latest\",  # fallback names\n",
        "]\n",
        "\n",
        "CHUNK_CHAR_LIMIT = 6000  # basic safety; adjust if you know token limits for your model\n",
        "\n",
        "def safe_print_md(md: str):\n",
        "    \"\"\"Render markdown safely in Colab.\"\"\"\n",
        "    display(Markdown(md))\n",
        "\n",
        "def load_api_key():\n",
        "    try:\n",
        "        key = userdata.get(\"GEMINI_API_KEY\")\n",
        "        genai.configure(api_key=key)\n",
        "        print(\"‚úÖ API key configured successfully from Colab Secrets.\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå Could not load GEMINI_API_KEY from Colab Secrets.\")\n",
        "        print(\"Details:\", e)\n",
        "        return False\n",
        "\n",
        "def list_available_models():\n",
        "    try:\n",
        "        models = list(genai.list_models())\n",
        "        # show names only\n",
        "        names = [m.name for m in models]\n",
        "        return names\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è Could not list models automatically. Exception:\", e)\n",
        "        return []\n",
        "\n",
        "def choose_best_model(available_names):\n",
        "    \"\"\"Pick a model from available_names based on DEFAULT_MODEL_PREFERENCES.\"\"\"\n",
        "    for pref in DEFAULT_MODEL_PREFERENCES:\n",
        "        if pref in available_names:\n",
        "            return pref\n",
        "    # fallback: prefer 'gemini-2.5-flash' if present substring match\n",
        "    for name in available_names:\n",
        "        if \"gemini-2.5-flash\" in name:\n",
        "            return name\n",
        "    # last resort: return first model\n",
        "    if available_names:\n",
        "        return available_names[0]\n",
        "    # if none available, return default preference first entry\n",
        "    return DEFAULT_MODEL_PREFERENCES[0]\n",
        "\n",
        "# --- Static analysis helpers ---\n",
        "def analyze_code_static(code: str):\n",
        "    \"\"\"Return simple static metrics: loops, functions, recursion detection, imports, lines.\"\"\"\n",
        "    results = {\"lines\": len(code.splitlines()), \"loops\": 0, \"functions\": 0, \"imports\": [], \"recursive_functions\": []}\n",
        "    try:\n",
        "        tree = ast.parse(code)\n",
        "    except Exception:\n",
        "        return results  # if parse fails, return minimal results\n",
        "    # Walk AST\n",
        "    func_defs = {}\n",
        "    for node in ast.walk(tree):\n",
        "        if isinstance(node, (ast.For, ast.While)):\n",
        "            results[\"loops\"] += 1\n",
        "        if isinstance(node, ast.FunctionDef):\n",
        "            results[\"functions\"] += 1\n",
        "            func_defs[node.name] = node\n",
        "        if isinstance(node, ast.Import):\n",
        "            for n in node.names:\n",
        "                results[\"imports\"].append(n.name)\n",
        "        if isinstance(node, ast.ImportFrom):\n",
        "            module = node.module or \"\"\n",
        "            for n in node.names:\n",
        "                results[\"imports\"].append(f\"{module}.{n.name}\" if module else n.name)\n",
        "    # detect recursion: function contains a call to itself\n",
        "    for fname, fnode in func_defs.items():\n",
        "        for sub in ast.walk(fnode):\n",
        "            if isinstance(sub, ast.Call):\n",
        "                if isinstance(sub.func, ast.Name) and sub.func.id == fname:\n",
        "                    results[\"recursive_functions\"].append(fname)\n",
        "                # method-style recursion detection (self.method())\n",
        "                if isinstance(sub.func, ast.Attribute) and isinstance(sub.func.value, ast.Name):\n",
        "                    # crude check: if attribute call name equals function name\n",
        "                    if sub.func.attr == fname:\n",
        "                        results[\"recursive_functions\"].append(fname)\n",
        "    # dedupe imports\n",
        "    results[\"imports\"] = sorted(list(set(results[\"imports\"])))\n",
        "    return results\n",
        "\n",
        "# --- Prompt builders ---\n",
        "def build_structured_prompt(code: str, filename: str = None, extra_instructions: str = None):\n",
        "    \"\"\"Return a prompt asking Gemini to produce a structured analysis.\"\"\"\n",
        "    header = f\"Analyze this Python code\"\n",
        "    if filename:\n",
        "        header += f\" from `{filename}`\"\n",
        "    header += \". Provide a structured response with numbered sections and clear labels.\"\n",
        "\n",
        "    instr_sections = [\n",
        "        \"1) Short Overview: 2-4 sentences describing what the code does at a high level.\",\n",
        "        \"2) Detailed Explanation: for each function and important block, explain what it does line-by-line or in small logical steps. Use bullet points and show relevant code snippets.\",\n",
        "        \"3) Algorithmic/Logic Summary & Complexity Analysis: describe the core algorithm(s), their time & space complexity (Big-O notation), and explain the reasoning.\",\n",
        "        \"4) Potential Issues & Bug Fixes: list likely runtime errors, input assumptions, corner cases, and provide corrected code snippets for any identified bugs.\",\n",
        "        \"5) Optimization suggestions & Optimized Code: provide practical improvements and quick wins (readability, performance, memory) and include a complete, optimized version of the code.\",\n",
        "        \"6) Test Ideas: suggest a few example inputs / test-cases (including edge cases) to validate the code, especially demonstrating bug fixes or optimizations.\",\n",
        "        \"7) Overall Summary/Comparison: Briefly compare the original and optimized code, highlighting the benefits.\",\n",
        "    ]\n",
        "    if extra_instructions:\n",
        "        instr_sections.append(\"8) Focus: \" + extra_instructions)\n",
        "\n",
        "    prompt = (\n",
        "        header + \"\\n\\n\"\n",
        "        + \"\\n\".join(instr_sections) + \"\\n\\n\"\n",
        "        + \"Format the response as Markdown with headers for each section and short code examples where helpful.\\n\"\n",
        "        + \"Ensure the Optimized Code section provides a complete, runnable version.\\n\\n\"\n",
        "        + \"Here is the code to analyze:\\n\\n\"\n",
        "        + \"```python\\n\"\n",
        "        + code\n",
        "        + \"\\n```\\n\"\n",
        "    )\n",
        "    return prompt\n",
        "\n",
        "def chunk_text(text: str, limit: int = CHUNK_CHAR_LIMIT):\n",
        "    \"\"\"Split text into chunks of approx 'limit' characters (split on newlines if possible).\"\"\"\n",
        "    if len(text) <= limit:\n",
        "        return [text]\n",
        "    lines = text.splitlines(keepends=True)\n",
        "    chunks = []\n",
        "    current = \"\"\n",
        "    for line in lines:\n",
        "        if len(current) + len(line) > limit and current:\n",
        "            chunks.append(current)\n",
        "            current = line\n",
        "        else:\n",
        "            current += line\n",
        "    if current:\n",
        "        chunks.append(current)\n",
        "    return chunks\n",
        "\n",
        "# --- Gemini call wrapper ---\n",
        "def call_gemini(prompt: str, model_name: str):\n",
        "    \"\"\"Call the configured Gemini model and return text. Handles errors and prints traceback.\"\"\"\n",
        "    try:\n",
        "        model = genai.GenerativeModel(model_name)\n",
        "        resp = model.generate_content(prompt)\n",
        "        # different SDK versions may return different fields; guard against None\n",
        "        if resp is None:\n",
        "            return None\n",
        "        # resp.text is typical\n",
        "        if hasattr(resp, \"text\"):\n",
        "            return resp.text\n",
        "        # attempt string conversion\n",
        "        return str(resp)\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è Exception while calling Gemini:\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "# --- Main interactive flow ---\n",
        "def run_intellicode_explainer():\n",
        "    print(\"# IntelliCode Explainer (Colab)\\n\")\n",
        "    ok = load_api_key()\n",
        "    if not ok:\n",
        "        print(\"Please add GEMINI_API_KEY to Colab Secrets and rerun this cell.\")\n",
        "        return\n",
        "\n",
        "    available = list_available_models()\n",
        "    if available:\n",
        "        print(\"Available models (sample):\")\n",
        "        for i, name in enumerate(available[:30], 1):\n",
        "            print(f\"  {i}. {name}\")\n",
        "        chosen = choose_best_model(available)\n",
        "        print(f\"\\n‚û°Ô∏è Auto-selected model: `{chosen}`\")\n",
        "    else:\n",
        "        chosen = DEFAULT_MODEL_PREFERENCES[0]\n",
        "        print(f\"‚ö†Ô∏è Could not query models. Defaulting to `{chosen}`. If this fails, set the model manually.\")\n",
        "\n",
        "    # allow user to override model\n",
        "    user_model = input(f\"\\nPress Enter to use `{chosen}`, or type another model name to use instead:\\n\").strip()\n",
        "    if user_model:\n",
        "        chosen = user_model\n",
        "\n",
        "    # upload mode\n",
        "    print(\"\\nUpload one or two Python files now (use the file picker).\")\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        print(\"No files uploaded ‚Äî aborting.\")\n",
        "        return\n",
        "\n",
        "    filenames = list(uploaded.keys())\n",
        "    if len(filenames) > 2:\n",
        "        print(\"You uploaded more than two files. This script will analyze only the first two.\")\n",
        "    file_a = filenames[0]\n",
        "    file_b = filenames[1] if len(filenames) > 1 else None\n",
        "\n",
        "    with open(file_a, \"r\", encoding=\"utf-8\") as f:\n",
        "        code_a = f.read()\n",
        "    code_b = None\n",
        "    if file_b:\n",
        "        with open(file_b, \"r\", encoding=\"utf-8\") as f:\n",
        "            code_b = f.read()\n",
        "\n",
        "    # static analysis\n",
        "    sa_a = analyze_code_static(code_a)\n",
        "    md_summary = f\"### üìä Static analysis summary for `{file_a}`\\n\"\n",
        "    md_summary += f\"- Lines: {sa_a['lines']}\\n- Functions: {sa_a['functions']}\\n- Loops (for/while): {sa_a['loops']}\\n\"\n",
        "    md_summary += f\"- Recursive functions: {sa_a['recursive_functions'] or 'None'}\\n- Imports: {sa_a['imports'] or 'None'}\\n\"\n",
        "    safe_print_md(md_summary)\n",
        "\n",
        "    if code_b:\n",
        "        sa_b = analyze_code_static(code_b)\n",
        "        md_summary_b = f\"### üìä Static analysis summary for `{file_b}`\\n\"\n",
        "        md_summary_b += f\"- Lines: {sa_b['lines']}\\n- Functions: {sa_b['functions']}\\n- Loops (for/while): {sa_b['loops']}\\n\"\n",
        "        md_summary_b += f\"- Recursive functions: {sa_b['recursive_functions'] or 'None'}\\n- Imports: {sa_b['imports'] or 'None'}\\n\"\n",
        "        safe_print_md(md_summary_b)\n",
        "\n",
        "    # extra instructions option\n",
        "    extra_instructions = input(\"\\nOptional: Type a focused instruction (e.g., 'explain only recursion' or press Enter to skip):\\n\").strip()\n",
        "    # build and possibly chunk prompt(s)\n",
        "    if code_b:\n",
        "        # Diff mode: ask for comparison + structured analysis\n",
        "        combined_prompt = (\n",
        "            \"You will receive two Python files: OLD and NEW. Provide a structured analysis focusing on the differences:\\n\\n\"\n",
        "            \"1) Short summary of each file (2-3 sentences).\\n\"\n",
        "            \"2) High-level differences: what changed between OLD and NEW.\\n\"\n",
        "            \"3) Functional / behavioral differences with examples.\\n\"\n",
        "            \"4) Possible regressions or performance impacts.\\n\"\n",
        "            \"5) Suggestions to improve or tests to run.\\n\\n\"\n",
        "            f\"OLD (`{file_a}`):\\n```python\\n{code_a}\\n```\\n\\n\"\n",
        "            f\"NEW (`{file_b}`):\\n```python\\n{code_b}\\n```\\n\"\n",
        "        )\n",
        "        if extra_instructions:\n",
        "            combined_prompt += \"\\nFocus: \" + extra_instructions + \"\\n\"\n",
        "        # chunking not necessary here unless super large; do a safety chunk\n",
        "        if len(combined_prompt) > CHUNK_CHAR_LIMIT:\n",
        "            safe_print_md(\"‚ö†Ô∏è Combined diff is large; splitting into chunks and asking the model to summarize differences. This may take multiple requests.\")\n",
        "            chunks = chunk_text(combined_prompt, CHUNK_CHAR_LIMIT)\n",
        "            responses = []\n",
        "            for i, ch in enumerate(chunks, 1):\n",
        "                safe_print_md(f\"#### Chunk {i}/{len(chunks)} ‚Äî sending to model `{chosen}`\")\n",
        "                resp = call_gemini(ch, chosen)\n",
        "                if resp:\n",
        "                    responses.append(resp)\n",
        "            # Naive aggregation: join responses and show\n",
        "            aggregated = \"\\n\\n---\\n\\n\".join(responses)\n",
        "            safe_print_md(\"### Aggregated model responses (raw):\\n\" + \"```\\n\" + aggregated[:30000] + \"\\n```\")\n",
        "            safe_print_md(\"‚ö†Ô∏è Aggregated output shown above. For a cleaner combined analysis, consider re-running with single-file mode or smaller files.\")\n",
        "        else:\n",
        "            safe_print_md(\"‚è≥ Sending diff to model...\")\n",
        "            resp = call_gemini(combined_prompt, chosen)\n",
        "            if resp:\n",
        "                safe_print_md(resp)\n",
        "            else:\n",
        "                safe_print_md(\"‚ö†Ô∏è No response from model. See logs above.\")\n",
        "    else:\n",
        "        # Single file analyze\n",
        "        chunks = chunk_text(code_a, CHUNK_CHAR_LIMIT)\n",
        "        if len(chunks) == 1:\n",
        "            prompt = build_structured_prompt(code_a, filename=file_a, extra_instructions=extra_instructions)\n",
        "            safe_print_md(\"‚è≥ Sending code to model for structured analysis...\")\n",
        "            resp = call_gemini(prompt, chosen)\n",
        "            if resp:\n",
        "                safe_print_md(resp)\n",
        "            else:\n",
        "                safe_print_md(\"‚ö†Ô∏è No response from model. See logs above.\")\n",
        "        else:\n",
        "            # chunked approach: ask for per-chunk analysis and then an overall summary pass\n",
        "            safe_print_md(f\"‚ö†Ô∏è File is large ({len(code_a)} chars). We'll analyze in {len(chunks)} chunks and then ask the model for an overall summary.\")\n",
        "            chunk_responses = []\n",
        "            for idx, ch in enumerate(chunks, 1):\n",
        "                safe_print_md(f\"#### Analyzing chunk {idx}/{len(chunks)} ...\")\n",
        "                prompt_chunk = build_structured_prompt(ch, filename=f\"{file_a} (chunk {idx}/{len(chunks)})\", extra_instructions=extra_instructions)\n",
        "                resp = call_gemini(prompt_chunk, chosen)\n",
        "                if resp:\n",
        "                    chunk_responses.append((idx, resp))\n",
        "                    # show an excerpt\n",
        "                    excerpt = resp[:8000]\n",
        "                    safe_print_md(f\"**Preview of chunk {idx} response (truncated):**\\n\\n```\\n{excerpt}\\n```\")\n",
        "                else:\n",
        "                    safe_print_md(f\"‚ö†Ô∏è No response for chunk {idx}.\")\n",
        "            # Combine chunk summaries and ask for a final aggregation\n",
        "            combined_summaries_text = \"\\n\\n\".join([f\"### Chunk {i}\\n{r}\" for i, r in chunk_responses])\n",
        "            final_prompt = (\n",
        "                \"You have been given chunked analyses of a single Python file.\\n\"\n",
        "                \"Each chunk analysis follows. Please produce a single consolidated, coherent structured analysis \"\n",
        "                \"that removes duplicate content, resolves cross-chunk references, and gives a final Overview, \"\n",
        "                \"Line-by-line guide (for key functions), Optimizations, and Test Ideas.\\n\\n\"\n",
        "                + combined_summaries_text\n",
        "            )\n",
        "            safe_print_md(\"‚è≥ Sending aggregation request to model...\")\n",
        "            final_resp = call_gemini(final_prompt, chosen)\n",
        "            if final_resp:\n",
        "                safe_print_md(final_resp)\n",
        "            else:\n",
        "                safe_print_md(\"‚ö†Ô∏è No aggregated response.\")\n",
        "\n",
        "    # Follow-up question loop (single round)\n",
        "    follow_up = input(\"\\nOptional: Ask a follow-up question about the analysis (press Enter to skip):\\n\").strip()\n",
        "    if follow_up:\n",
        "        # Provide the code context and the user's question\n",
        "        follow_prompt = (\n",
        "            \"The user previously received a structured analysis for the following code. \"\n",
        "            \"Please answer the user's follow-up question concisely and reference code lines or functions where appropriate.\\n\\n\"\n",
        "            f\"Code (`{file_a}`):\\n```python\\n{code_a}\\n```\\n\\n\"\n",
        "            f\"User question: {follow_up}\\n\\n\"\n",
        "            \"Answer in Markdown, with examples if relevant.\"\n",
        "        )\n",
        "        safe_print_md(\"‚è≥ Sending follow-up question to model...\")\n",
        "        follow_resp = call_gemini(follow_prompt, chosen)\n",
        "        if follow_resp:\n",
        "            safe_print_md(follow_resp)\n",
        "        else:\n",
        "            safe_print_md(\"‚ö†Ô∏è No response to follow-up question.\")\n",
        "\n",
        "    print(\"\\n‚úÖ Done. You can re-run the cell to analyze other files or change the model.\")\n",
        "\n",
        "# entrypoint\n",
        "run_intellicode_explainer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_65NEQG6_nAb",
        "outputId": "896a1b41-7b85-480d-8cea-51343ab10fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# IntelliCode Explainer (Colab)\n",
            "\n",
            "‚úÖ API key configured successfully from Colab Secrets.\n",
            "Available models (sample):\n",
            "  1. models/embedding-gecko-001\n",
            "  2. models/gemini-2.5-pro-preview-03-25\n",
            "  3. models/gemini-2.5-flash-preview-05-20\n",
            "  4. models/gemini-2.5-flash\n",
            "  5. models/gemini-2.5-flash-lite-preview-06-17\n",
            "  6. models/gemini-2.5-pro-preview-05-06\n",
            "  7. models/gemini-2.5-pro-preview-06-05\n",
            "  8. models/gemini-2.5-pro\n",
            "  9. models/gemini-2.0-flash-exp\n",
            "  10. models/gemini-2.0-flash\n",
            "  11. models/gemini-2.0-flash-001\n",
            "  12. models/gemini-2.0-flash-exp-image-generation\n",
            "  13. models/gemini-2.0-flash-lite-001\n",
            "  14. models/gemini-2.0-flash-lite\n",
            "  15. models/gemini-2.0-flash-preview-image-generation\n",
            "  16. models/gemini-2.0-flash-lite-preview-02-05\n",
            "  17. models/gemini-2.0-flash-lite-preview\n",
            "  18. models/gemini-2.0-pro-exp\n",
            "  19. models/gemini-2.0-pro-exp-02-05\n",
            "  20. models/gemini-exp-1206\n",
            "  21. models/gemini-2.0-flash-thinking-exp-01-21\n",
            "  22. models/gemini-2.0-flash-thinking-exp\n",
            "  23. models/gemini-2.0-flash-thinking-exp-1219\n",
            "  24. models/gemini-2.5-flash-preview-tts\n",
            "  25. models/gemini-2.5-pro-preview-tts\n",
            "  26. models/learnlm-2.0-flash-experimental\n",
            "  27. models/gemma-3-1b-it\n",
            "  28. models/gemma-3-4b-it\n",
            "  29. models/gemma-3-12b-it\n",
            "  30. models/gemma-3-27b-it\n",
            "\n",
            "‚û°Ô∏è Auto-selected model: `models/gemini-2.5-flash`\n",
            "\n",
            "Press Enter to use `models/gemini-2.5-flash`, or type another model name to use instead:\n",
            "models/gemini-2.5-flash\n",
            "\n",
            "Upload one or two Python files now (use the file picker).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-250e9684-85ba-4e19-b08f-8bcdc74f0198\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-250e9684-85ba-4e19-b08f-8bcdc74f0198\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving majorityelement.py to majorityelement (1).py\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### üìä Static analysis summary for `majorityelement (1).py`\n- Lines: 17\n- Functions: 1\n- Loops (for/while): 2\n- Recursive functions: None\n- Imports: ['typing.List']\n"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Optional: Type a focused instruction (e.g., 'explain only recursion' or press Enter to skip):\n",
            "enter\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "‚è≥ Sending code to model for structured analysis..."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here's a structured analysis of the provided Python code.\n\n---\n\n### 1) Short Overview\n\nThe Python code defines a `Solution` class with a `majorityElement` method. This method aims to find the \"majority element\" in a given list of integers, where the majority element is defined as the number that appears more than `len(nums) // 2` times. It achieves this by counting the occurrences of each number using a dictionary and then iterating through the dictionary to find the number whose count exceeds the calculated threshold.\n\n---\n\n### 2) Detailed Explanation\n\nThe code processes a list of integers to identify the majority element.\n\n*   **`from typing import List`**\n    *   Imports the `List` type from the `typing` module. This is used for type hinting, improving code readability and enabling static analysis tools to check types.\n*   **`class Solution:`**\n    *   Defines a class named `Solution`. This is a common practice in competitive programming platforms (like LeetCode) where the solution logic is encapsulated within a class.\n*   **`def majorityElement(self, nums: List[int]) -> int:`**\n    *   Defines a method named `majorityElement` within the `Solution` class.\n    *   `self`: A reference to the instance of the class (standard for instance methods).\n    *   `nums: List[int]`: Specifies that the `nums` parameter is expected to be a list of integers.\n    *   `-> int`: Indicates that the method is expected to return an integer.\n*   **`temp = len(nums) // 2`**\n    *   Calculates the threshold for what constitutes a \"majority.\"\n    *   `len(nums)`: Gets the total number of elements in the input list `nums`.\n    *   `// 2`: Performs integer division by 2. This means, for example, if `len(nums)` is 5, `temp` will be 2 (a majority element must appear more than 2 times, i.e., 3 or more times).\n*   **`dici = {}`**\n    *   Initializes an empty dictionary named `dici` (likely short for \"dictionary\"). This dictionary will be used to store the frequency (count) of each unique number encountered in `nums`. The keys will be the numbers, and the values will be their counts.\n*   **`for i in nums:`**\n    *   Starts a loop that iterates through each element `i` in the input list `nums`.\n*   **`if i not in dici:`**\n    *   Checks if the current number `i` is already a key in the `dici` dictionary.\n    *   If `i` is not in `dici`, it means this is the first time we've encountered this number.\n*   **`dici[i] = 1`**\n    *   If `i` is new, add it to the `dici` dictionary as a key with an initial count of `1`.\n*   **`else:`**\n    *   If `i` is already in `dici`, it means we've seen this number before.\n*   **`dici[i] += 1`**\n    *   Increment the count associated with the key `i` in the `dici` dictionary by `1`.\n    *   *This entire `for` loop efficiently builds a frequency map of all numbers in `nums`.*\n*   **`for i in dici:`**\n    *   Starts a second loop, this time iterating through the *keys* (the unique numbers) of the `dici` dictionary.\n*   **`if dici[i] > temp:`**\n    *   For each number `i` (key) in `dici`, it checks if its corresponding count (`dici[i]`) is greater than the `temp` threshold calculated earlier (`len(nums) // 2`).\n*   **`return i`**\n    *   If a number's count exceeds the `temp` threshold, that number is the majority element, and the method immediately returns it. The problem typically guarantees that such an element exists.\n*   **`nums = list(map(int,input().split()))`**\n    *   This line handles user input to test the `majorityElement` method.\n    *   `input()`: Reads a line of text from standard input (e.g., \"1 2 2 3 2\").\n    *   `.split()`: Splits the input string by whitespace into a list of strings (e.g., `['1', '2', '2', '3', '2']`).\n    *   `map(int, ...)`: Applies the `int()` function to each string in the list, converting them to integers (e.g., `[1, 2, 2, 3, 2]`).\n    *   `list(...)`: Converts the `map` object into an actual list.\n*   **`obj = Solution()`**\n    *   Creates an instance of the `Solution` class.\n*   **`print(obj.majorityElement(nums))`**\n    *   Calls the `majorityElement` method on the `obj` instance, passing the user-provided `nums` list. The returned majority element is then printed to the console.\n\n---\n\n### 3) Algorithmic/Logic Summary & Complexity Analysis\n\n*   **Core Algorithm/Logic**:\n    1.  Calculate the majority threshold (`n/2`).\n    2.  Iterate through the input list once to count the frequency of each element using a hash map (Python dictionary).\n    3.  Iterate through the keys (elements) of the hash map.\n    4.  Return the first element whose frequency is greater than the majority threshold. The problem implicitly guarantees that such an element exists.\n\n*   **Time Complexity**:\n    *   `temp = len(nums) // 2`: O(1)\n    *   First loop (`for i in nums`): Iterates `n` times, where `n` is `len(nums)`. Dictionary operations (insertion, lookup, update) on average take O(1) time. Therefore, this loop contributes O(n).\n    *   Second loop (`for i in dici`): In the worst case, all elements in `nums` are distinct, meaning `dici` will have `n` entries. Iterating through `n` entries and performing a dictionary lookup (O(1) on average) contributes O(n).\n    *   **Total Time Complexity: O(n)**, as the dominant operations are the two linear traversals.\n\n*   **Space Complexity**:\n    *   `dici = {}`: In the worst case, if all elements in `nums` are distinct, the dictionary `dici` will store `n` key-value pairs. Each key and value takes constant space.\n    *   **Total Space Complexity: O(n)**, due to the storage required for the frequency dictionary.\n\n---\n\n### 4) Potential Issues & Bug Fixes\n\n1.  **Empty List Input**:\n    *   **Issue**: If `nums` is an empty list (`[]`), `len(nums) // 2` becomes `0`. The first `for` loop won't execute, `dici` remains empty. The second `for` loop also won't execute. The function will implicitly return `None`, which is generally not a desired outcome for a function declared to return `int`.\n    *   **Assumption**: Standard \"Majority Element\" problems (e.g., LeetCode) often state that the input array is non-empty and a majority element *always* exists. If this assumption holds, the empty list case is not a concern for correctness.\n    *   **Bug Fix (if empty list is possible and needs handling)**:\n        ```python\n        class Solution:\n            def majorityElement(self, nums: List[int]) -> int:\n                if not nums:\n                    # Or return a specific sentinel value like -1 if appropriate,\n                    # or raise an error as there's no majority element in an empty list.\n                    raise ValueError(\"Input list cannot be empty.\")\n                # ... rest of the original code ...\n        ```\n2.  **No Majority Element (If not guaranteed by problem statement)**:\n    *   **Issue**: If the input list `nums` does *not* contain a majority element (e.g., `[1, 2, 3, 4]`), the current code would iterate through all elements in `dici`, but `dici[i] > temp` would never be true. Consequently, the function would complete without executing a `return` statement, implicitly returning `None`.\n    *   **Assumption**: The standard problem statement guarantees that a majority element always exists.\n    *   **Bug Fix (if no majority element is possible)**:\n        ```python\n        class Solution:\n            def majorityElement(self, nums: List[int]) -> int:\n                # ... existing code up to the second loop ...\n                for i in dici:\n                    if dici[i] > temp:\n                        return i\n                # If the loop finishes without returning, no majority element was found.\n                raise ValueError(\"No majority element found in the list.\")\n        ```\n\nFor the typical constraints of the Majority Element problem, where the list is non-empty and a majority element is guaranteed, the original code is logically sound and bug-free within those assumptions.\n\n---\n\n### 5) Optimization suggestions & Optimized Code\n\nThe original code is already O(n) time, which is optimal for algorithms that must read all input elements. However, its space complexity is O(n), which can be improved. A well-known algorithm for this problem, **Boyer-Moore Voting Algorithm**, achieves O(1) space complexity.\n\n**Optimization Idea (Boyer-Moore Voting Algorithm):**\n\nThis algorithm works on the principle that if a majority element exists, it will \"outvote\" all other elements.\n1.  Initialize a `candidate` variable to store the potential majority element and a `count` to 0.\n2.  Iterate through the list:\n    *   If `count` is 0, set the current element as the `candidate` and set `count` to 1.\n    *   If the current element is the `candidate`, increment `count`.\n    *   If the current element is different from the `candidate`, decrement `count`.\n3.  The final `candidate` will be the majority element (guaranteed by the problem statement).\n\n**Benefits:**\n*   **Space**: O(1) constant space (only a few variables needed).\n*   **Time**: O(n) single pass through the array.\n\n**Optimized Code:**\n\n```python\nfrom typing import List\n\nclass Solution:\n    def majorityElement(self, nums: List[int]) -> int:\n        # According to the problem statement for the Majority Element,\n        # the input list `nums` is guaranteed to be non-empty,\n        # and a majority element (which appears more than n/2 times) always exists.\n\n        candidate = None\n        count = 0\n\n        for num in nums:\n            if count == 0:\n                # If count is 0, the current candidate has been \"cancelled out\" by other numbers.\n                # Start a new \"vote\" with the current number.\n                candidate = num\n                count = 1\n            elif num == candidate:\n                # If the current number is the same as the candidate, increment its vote.\n                count += 1\n            else:\n                # If the current number is different, it cancels out one vote for the candidate.\n                count -= 1\n        \n        # After iterating through all numbers, the 'candidate' will hold the majority element.\n        # No second pass is needed to verify its count if a majority element is guaranteed.\n        return candidate\n\n# Example usage for testing the optimized code\nif __name__ == '__main__':\n    try:\n        nums_input_str = input(\"Enter numbers separated by spaces (e.g., 3 2 3): \")\n        nums = list(map(int, nums_input_str.split()))\n\n        # Add a check for empty input if not guaranteed non-empty by problem\n        if not nums:\n            print(\"Error: Input list cannot be empty.\")\n        else:\n            obj = Solution()\n            result = obj.majorityElement(nums)\n            print(f\"The majority element is: {result}\")\n    except ValueError as e:\n        print(f\"Error processing input: {e}. Please enter space-separated integers.\")\n\n```\n\n---\n\n### 6) Test Ideas\n\nHere are some test cases to validate the code, including edge cases:\n\n*   **Standard Case (Odd Length):**\n    *   Input: `3 2 3`\n    *   Expected Output: `3` (3 appears 2 times, `len/2 = 1.5`, `2 > 1.5`)\n*   **Standard Case (Even Length):**\n    *   Input: `2 2 1 1 1 2 2`\n    *   Expected Output: `2` (2 appears 4 times, `len/2 = 3.5`, `4 > 3.5`)\n*   **Majority Element at Beginning:**\n    *   Input: `7 7 7 1 2`\n    *   Expected Output: `7`\n*   **Majority Element at End:**\n    *   Input: `1 2 7 7 7`\n    *   Expected Output: `7`\n*   **All Elements are Majority:**\n    *   Input: `6 6 6 6`\n    *   Expected Output: `6`\n*   **Single Element List (Edge Case):**\n    *   Input: `1`\n    *   Expected Output: `1` (`len/2 = 0.5`, `1 > 0.5`)\n*   **Negative Numbers:**\n    *   Input: `-1 -1 2 -1`\n    *   Expected Output: `-1`\n*   **Large Numbers:**\n    *   Input: `1000000000 1000000000 5 1000000000`\n    *   Expected Output: `1000000000`\n*   **Mixed positive/negative/zero:**\n    *   Input: `0 0 1 0 2`\n    *   Expected Output: `0`\n\n---\n\n### 7) Overall Summary/Comparison\n\nThe **original code** correctly solves the Majority Element problem using a hash map (dictionary) to store frequencies. It's conceptually straightforward and easy to understand. Its time complexity is **O(n)**, which is efficient, but its space complexity is also **O(n)** because the dictionary can grow proportionally to the number of distinct elements in the input list.\n\nThe **optimized code** (using the Boyer-Moore Voting Algorithm) also correctly solves the problem and achieves the optimal time complexity of **O(n)**. However, its significant advantage is its space complexity, which is **O(1)**. This means it uses a constant amount of extra memory regardless of the input list's size. For very large datasets, the O(1) space complexity of the Boyer-Moore algorithm is highly preferable as it avoids potential memory exhaustion and offers superior performance in memory-constrained environments. While slightly less intuitive initially, it's the more efficient and often preferred solution for this specific problem due to its minimal memory footprint."
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Optional: Ask a follow-up question about the analysis (press Enter to skip):\n",
            "enter\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "‚è≥ Sending follow-up question to model..."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This Python code defines the `majorityElement` function (lines 3-16) to find the element that appears more than `len(nums) // 2` times in the input list `nums`.\n\nIt achieves this by:\n1.  Calculating the required majority threshold (`temp = len(nums) // 2` on line 5).\n2.  Building a frequency map using a dictionary (`dici`, lines 6-12) to count occurrences of each number.\n3.  Iterating through `dici` (lines 14-16) to return the first number whose count exceeds the `temp` threshold."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Done. You can re-run the cell to analyze other files or change the model.\n"
          ]
        }
      ]
    }
  ]
}